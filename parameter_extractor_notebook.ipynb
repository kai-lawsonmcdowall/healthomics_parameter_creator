{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_substrings(input_string: str, keyword: str):\n",
    "    \"\"\"\n",
    "    Extracts substrings enclosed between <code>--{keyword}</code> and <code>-- tags\n",
    "    from the given input_string. These substrings and their contents are unique to each nf-core parameter listed on the nf-core\n",
    "    page, therefore, we can use them to determine if a parameter is required or optional.\n",
    "\n",
    "    Args:\n",
    "        input_string (str): The html content of the workflow nf-core params page, as a giant string\n",
    "        keyword (str): The keyword to identify substrings between <code>--{keyword}</code> tags.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted substrings, each of which will contain the optional or required statement of each parameter\n",
    "        listed in the nf-core workflow params page.\n",
    "    \"\"\"\n",
    "\n",
    "    substrings = []\n",
    "    start_pattern = re.escape(f\"<code>--{keyword}</code>\")\n",
    "    end_pattern = re.escape(\"<code>--\")\n",
    "    pattern = re.compile(r\"{}(.*?){}\".format(start_pattern, end_pattern), re.DOTALL)\n",
    "    matches = pattern.findall(input_string)\n",
    "    for match in matches:\n",
    "        substrings.append(match.strip())\n",
    "    return substrings\n",
    "\n",
    "\n",
    "def process_json(input_string: str, json_data: dict):\n",
    "    \"\"\"\n",
    "    Process the input string to update the 'optional' status in the eventual parameter-description.json\n",
    "    based on the presence of specific substrings associated with each keyword. This function modifies the\n",
    "    'optional' status in the 'json_data' dictionary in place.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        input_string (str): The input string to search for substrings.\n",
    "        json_data (dict): A dictionary containing keyword-substring mappings.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    for keyword in json_data.keys():\n",
    "        print(f\"getting required status for {keyword}\")\n",
    "        substrings = extract_substrings(input_string, keyword)\n",
    "        for idx, substring in enumerate(substrings, 1):\n",
    "            if (\n",
    "                'class=\"badge text-bg-warning mb-1\" data-svelte-h=\"svelte-1t99nzu\">required</span>'\n",
    "                in substring\n",
    "            ):\n",
    "                json_data[keyword][\"optional\"] = False\n",
    "            else:\n",
    "                json_data[keyword][\"optional\"] = True\n",
    "\n",
    "\n",
    "def create_parameters_json(\n",
    "    nextflow_schema: str, nf_core_params_url: str, json_output_path: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a JSON file containing parameters extracted from a Nextflow schema and nf-core parameters URL.\n",
    "\n",
    "    Parameters:\n",
    "        nextflow_schema (str): Path to the Nextflow schema JSON file.\n",
    "        nf_core_params_url (str): URL of the nf-core parameters page of the workflow.\n",
    "        json_output_path (str): Path to write the output JSON file containing extracted parameters.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    This function loads the original Nextflow schema JSON file and fetches the HTML content of the nf-core parameters\n",
    "    page. It extracts parameter titles and descriptions from the Nextflow schema and determines if each parameter is\n",
    "    required or optional based on the HTML content. The extracted data is written to a new JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the original JSON file\n",
    "    with open(nextflow_schema, \"r\") as f:\n",
    "        original_data = json.load(f)\n",
    "\n",
    "    # Fetching the HTML content of the workflow's nf-core params page\n",
    "    response = requests.get(nf_core_params_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        html_string = str(soup)\n",
    "\n",
    "    # Initialize an empty dictionary to store extracted data\n",
    "    extracted_data = {}\n",
    "\n",
    "    # List of parameters to exclude from the final JSON\n",
    "    exclude_parameters = [\n",
    "        \"outdir\",\n",
    "        \"email\",\n",
    "        \"custom_config_version\",\n",
    "        \"custom_config_base\",\n",
    "        \"config_profile_name\",\n",
    "        \"config_profile_description\",\n",
    "        \"config_profile_contact\",\n",
    "        \"config_profile_url\",\n",
    "        \"max_cpus\",\n",
    "        \"max_memory\",\n",
    "        \"max_time\",\n",
    "        \"help\",\n",
    "        \"version\",\n",
    "        \"publish_dir_mode\",\n",
    "        \"email_on_fail\",\n",
    "        \"plaintext_email\",\n",
    "        \"monochrome_logs\",\n",
    "        \"hook_url\",\n",
    "        \"validate_params\",\n",
    "        \"validationShowHiddenParams\",\n",
    "        \"validationFailUnrecognisedParams\",\n",
    "        \"validationLenientMode\",\n",
    "    ]\n",
    "\n",
    "    # Iterate over each definition in the Nextflow schema\n",
    "    for definition_key, definition_value in original_data.get(\n",
    "        \"definitions\", {}\n",
    "    ).items():\n",
    "        # Check if the definition has properties\n",
    "        if \"properties\" in definition_value:\n",
    "            # Iterate over each property in the definition\n",
    "            for property_key, property_value in definition_value[\"properties\"].items():\n",
    "                # Skip excluded parameters\n",
    "                if property_key in exclude_parameters:\n",
    "                    continue\n",
    "\n",
    "                # Extract title and description\n",
    "                title = property_key\n",
    "                description = property_value.get(\"description\", \"\")\n",
    "\n",
    "                # Set optional field to an empty string\n",
    "                extracted_data[title] = {\"optional\": \"\", \"description\": description}\n",
    "\n",
    "    # Getting if the parameter is required or optional\n",
    "    process_json(html_string, extracted_data)\n",
    "\n",
    "    # Convert \"optional\": \"\" to \"optional\": true if empty\n",
    "    for key, value in extracted_data.items():\n",
    "        if value[\"optional\"] == \"\":\n",
    "            extracted_data[key][\"optional\"] = True\n",
    "\n",
    "    # Write the extracted data to a new JSON file\n",
    "    with open(json_output_path, \"w\") as f:\n",
    "        json.dump(extracted_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example usage - fetchngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting required status for input\n",
      "getting required status for ena_metadata_fields\n",
      "getting required status for sample_mapping_fields\n",
      "getting required status for nf_core_pipeline\n",
      "getting required status for nf_core_rnaseq_strandedness\n",
      "getting required status for download_method\n",
      "getting required status for skip_fastq_download\n",
      "getting required status for dbgap_key\n",
      "getting required status for force_sratools_download\n"
     ]
    }
   ],
   "source": [
    "create_parameters_json(\n",
    "    \"tests/fetchngs_nextflow_schema.json\",\n",
    "    \"https://nf-co.re/fetchngs/1.12.0/parameters\",\n",
    "    \"outputs/NOTEBOOK_fetchngs_parameter_template.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example usage - sarek \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting required status for step\n",
      "getting required status for input\n",
      "getting required status for split_fastq\n",
      "getting required status for wes\n",
      "getting required status for intervals\n",
      "getting required status for nucleotides_per_second\n",
      "getting required status for no_intervals\n",
      "getting required status for tools\n",
      "getting required status for skip_tools\n",
      "getting required status for trim_fastq\n",
      "getting required status for clip_r1\n",
      "getting required status for clip_r2\n",
      "getting required status for three_prime_clip_r1\n",
      "getting required status for three_prime_clip_r2\n",
      "getting required status for trim_nextseq\n",
      "getting required status for save_trimmed\n",
      "getting required status for umi_read_structure\n",
      "getting required status for group_by_umi_strategy\n",
      "getting required status for save_split_fastqs\n",
      "getting required status for aligner\n",
      "getting required status for save_mapped\n",
      "getting required status for save_output_as_bam\n",
      "getting required status for use_gatk_spark\n",
      "getting required status for concatenate_vcfs\n",
      "getting required status for only_paired_variant_calling\n",
      "getting required status for joint_germline\n",
      "getting required status for ascat_min_base_qual\n",
      "getting required status for ascat_min_counts\n",
      "getting required status for ascat_min_map_qual\n",
      "getting required status for ascat_ploidy\n",
      "getting required status for ascat_purity\n",
      "getting required status for cf_chrom_len\n",
      "getting required status for cf_coeff\n",
      "getting required status for cf_contamination_adjustment\n",
      "getting required status for cf_contamination\n",
      "getting required status for cf_minqual\n",
      "getting required status for cf_mincov\n",
      "getting required status for cf_ploidy\n",
      "getting required status for cf_window\n",
      "getting required status for cnvkit_reference\n",
      "getting required status for pon\n",
      "getting required status for pon_tbi\n",
      "getting required status for ignore_soft_clipped_bases\n",
      "getting required status for vep_include_fasta\n",
      "getting required status for vep_dbnsfp\n",
      "getting required status for dbnsfp\n",
      "getting required status for dbnsfp_tbi\n",
      "getting required status for dbnsfp_consequence\n",
      "getting required status for dbnsfp_fields\n",
      "getting required status for vep_loftee\n",
      "getting required status for vep_spliceai\n",
      "getting required status for spliceai_snv\n",
      "getting required status for spliceai_snv_tbi\n",
      "getting required status for spliceai_indel\n",
      "getting required status for spliceai_indel_tbi\n",
      "getting required status for vep_spliceregion\n",
      "getting required status for vep_custom_args\n",
      "getting required status for snpeff_cache\n",
      "getting required status for vep_cache\n",
      "getting required status for outdir_cache\n",
      "getting required status for vep_out_format\n",
      "getting required status for genome\n",
      "getting required status for ascat_genome\n",
      "getting required status for ascat_alleles\n",
      "getting required status for ascat_loci\n",
      "getting required status for ascat_loci_gc\n",
      "getting required status for ascat_loci_rt\n",
      "getting required status for bwa\n",
      "getting required status for bwamem2\n",
      "getting required status for chr_dir\n",
      "getting required status for dbsnp\n",
      "getting required status for dbsnp_tbi\n",
      "getting required status for dbsnp_vqsr\n",
      "getting required status for dict\n",
      "getting required status for dragmap\n",
      "getting required status for fasta\n",
      "getting required status for fasta_fai\n",
      "getting required status for germline_resource\n",
      "getting required status for germline_resource_tbi\n",
      "getting required status for known_indels\n",
      "getting required status for known_indels_tbi\n",
      "getting required status for known_indels_vqsr\n",
      "getting required status for known_snps\n",
      "getting required status for known_snps_tbi\n",
      "getting required status for known_snps_vqsr\n",
      "getting required status for mappability\n",
      "getting required status for snpeff_db\n",
      "getting required status for snpeff_genome\n",
      "getting required status for snpeff_version\n",
      "getting required status for vep_genome\n",
      "getting required status for vep_species\n",
      "getting required status for vep_cache_version\n",
      "getting required status for vep_version\n",
      "getting required status for save_reference\n",
      "getting required status for build_only_index\n",
      "getting required status for download_cache\n",
      "getting required status for igenomes_base\n",
      "getting required status for igenomes_ignore\n",
      "getting required status for test_data_base\n",
      "getting required status for seq_center\n",
      "getting required status for seq_platform\n",
      "getting required status for ecr_registry\n",
      "getting required status for max_multiqc_email_size\n",
      "getting required status for multiqc_title\n",
      "getting required status for multiqc_config\n",
      "getting required status for multiqc_logo\n",
      "getting required status for multiqc_methods_description\n",
      "getting required status for tracedir\n",
      "getting required status for show_hidden_params\n"
     ]
    }
   ],
   "source": [
    "create_parameters_json(\n",
    "    \"tests/sarek_nextflow_schema.json\",\n",
    "    \"https://nf-co.re/sarek/3.4.2/parameters/\",\n",
    "    \"outputs/NOTEBOOK_sarek_parameter_template.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
